#!/usr/bin/env python3
import copy
import os
import re
import warnings
import click
import pickle

import tensorflow as tf
import numpy as np
import pandas as pd

from tqdm import tqdm
from glob import glob
from matplotlib import pyplot as plt
from typing import Tuple

from vbfml.util import (
    DatasetAndLabelConfiguration,
    get_process_tag_from_file,
    vbfml_path,
)
from vbfml.plot.util import Quantity
from vbfml.training.util import summarize_datasets, select_and_label_datasets
from vbfml.training.data import TrainingLoader
from vbfml.training.plot import ImagePlotter
from vbfml.training.input import build_sequence, load_datasets_bucoffea

warnings.filterwarnings("ignore", category=pd.errors.PerformanceWarning)

pjoin = os.path.join


def load_cache(input_dir: str) -> tuple:
    """
    Load prediction data from cache and return it.
    """
    cache_file = pjoin(input_dir, "predict_cache.pkl")
    assert os.path.exists(cache_file), f"Cannot find file: {cache_file}"
    with open(cache_file, "rb") as f:
        cache = pickle.load(f)

    df = cache["df_non_feature"]
    predictions = cache["predictions"]
    label_encoding = cache["label_encoding"]

    return df, predictions, label_encoding


@click.group()
def cli():
    pass


@cli.command()
@click.pass_context
@click.option(
    "-i",
    "--input-files",
    required=True,
    help="Path to the directory with the input ROOT files.",
)
@click.option(
    "-m",
    "--model-path",
    required=True,
    help="Path to the model directory.",
)
@click.option(
    "-t",
    "--tag",
    required=True,
    help="Tag to identify the process.",
)
@click.option(
    "--save-images",
    is_flag=True,
    help="If specified, the images will be saved as another pkl file within the directory.",
)
def predict(
    ctx, input_files: str, model_path: str, tag: str, save_images: bool = False
) -> None:
    """
    Read events from the input_files, make predictions
    with the pre-trained model (read from model_path) and save the
    predictions, together with other event data for later use.

    input_files can be either a single file, or can contain an asterisk (*)
    to specify multiple files.
    """
    # Create a list of DatasetInfo objects for the files that we are interested in
    directory, file_pattern = os.path.dirname(input_files), os.path.basename(
        input_files
    )
    datasets = load_datasets_bucoffea(directory, file_pattern)
    # Get datasets and corresponding labels from datasets.yml
    datasets_path = vbfml_path("config/datasets/datasets.yml")
    dataset_config = DatasetAndLabelConfiguration(datasets_path)

    dataset_labels = dataset_config.get_dataset_labels()
    datasets = select_and_label_datasets(datasets, dataset_labels)
    summarize_datasets(datasets)

    high_level_features = [
        "mjj",
        "detajj",
        "njet",
        "njet_pt30",
        "njet_central",
        "njet_forward",
        "recoil_pt",
        "recoil_phi",
        "leadak4_pt",
        "trailak4_pt",
        "leadak4_eta",
        "trailak4_eta",
        "leadak4_phi",
        "trailak4_phi",
        "ak4_pt2",
        "ak4_eta2",
        "ak4_phi2",
    ]

    # read feature from pkl file
    with open(model_path + "/features.pkl", "rb") as f:
        image_features = pickle.load(f)

    # Validation sequence: Read the last 20% of events
    read_range = (0.8, 1.0)

    # Two separate validation sequences for high_level features (e.g. mjj) and image features:
    # We'll make the predictions based on the image features, but we'll plot the
    # high-level quantities at the end
    validation_sequences = {}

    validation_sequences["high_level"] = build_sequence(
        datasets=copy.deepcopy(datasets),
        features=high_level_features,
        weight_expression="weight_total*xs/sumw",
        shuffle=True,
        scale_features="none",
    )
    validation_sequences["high_level"].batch_size = int(1e6)
    validation_sequences["high_level"].batch_buffer_size = 1

    validation_sequences["image"] = build_sequence(
        datasets=copy.deepcopy(datasets),
        features=image_features,
        weight_expression="weight_total*xs/sumw",
        shuffle=True,
        scale_features="norm",
    )

    validation_sequences["image"].batch_size = int(1e3)
    validation_sequences["image"].batch_buffer_size = 10

    for sequence in validation_sequences.values():
        sequence.read_range = read_range

    # Load the pre-trained model
    loader = TrainingLoader(model_path)
    model = loader.get_model()

    # Retrieve the label encoding from the original training sequence
    # so that we have the correct integer to label mapping
    training_sequence = loader.get_sequence("training")
    temp = training_sequence.label_encoding
    # Clean the non-int keys
    label_encoding = {k: v for k, v in temp.items() if isinstance(k, int)}

    predictions = []
    image_pixels = []
    for ibatch in tqdm(
        range(len(validation_sequences["image"])), desc="Making predictions"
    ):
        features, _, _ = validation_sequences["image"][ibatch]
        predictions.append(model.predict(features).argmax(axis=1))
        image_pixels.append(features)

    predictions = np.concatenate(predictions)
    image_pixels = np.concatenate(image_pixels)

    # High-level features
    for ibatch in tqdm(
        range(len(validation_sequences["high_level"])),
        desc="Obtaining high-level features",
    ):
        # Fill the sequence buffer if the batch is not there
        validation_sequences["high_level"][ibatch]
        df_non_feature = validation_sequences["high_level"].buffer.get_batch_df(ibatch)
        df_non_feature.drop(columns=["label"], inplace=True)

    outdir = pjoin(model_path, f"predictions_{tag.lower()}")
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    # Dump the input file argument to a txt file
    input_list_file = pjoin(outdir, "input_root_files.txt")
    with open(input_list_file, "w+") as f:
        for infile in glob(input_files):
            f.write(f"{infile}\n")

    # Save everything into a cache.pkl file
    cache = {
        "predictions": predictions,
        "df_non_feature": df_non_feature,
        "label_encoding": label_encoding,
    }

    cache_file = pjoin(outdir, "predict_cache.pkl")
    with open(cache_file, "wb+") as f:
        pickle.dump(cache, f)

    # Also save the image arrays for later use, if requested specifically
    if save_images:
        images_cache = pjoin(outdir, "images.pkl")
        with open(images_cache, "wb+") as f:
            pickle.dump(image_pixels, f)


@cli.command()
@click.pass_context
@click.argument("input_dir")
@click.option("-n", "--normalize", is_flag=True, help="Normalize the histogram plots.")
def plot(ctx, input_dir: str, normalize: bool) -> None:
    """
    Make histogram of high-level features, split by the predicted class,
    and plot the histograms.
    """
    df, predictions, label_encoding = load_cache(input_dir)

    process_tag = os.path.basename(input_dir.rstrip("/")).replace("predictions_", "")

    outdir = pjoin(input_dir, "plots")
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    # Based on the predictions, we make histograms for different classes
    quantities = [x for x in list(df.columns) if x != "weight"]

    for quantity_name in tqdm(quantities, desc="Plotting histograms"):
        quantity = Quantity(quantity_name)
        fig, ax = plt.subplots()
        for icls, sample_cls in label_encoding.items():
            mask = predictions == icls
            try:
                ax.hist(
                    df[quantity_name][mask],
                    histtype="step",
                    weights=df["weight"][mask],
                    bins=quantity.bins,
                    label=sample_cls,
                    density=normalize,
                )
            except KeyError:
                print(f"WARNING: Cannot find {quantity_name} in dataframe, skipping.")
                continue

        ax.set_xlabel(quantity.label, fontsize=14)
        if normalize:
            ax.set_ylabel("Weighted Counts (Norm.)", fontsize=14)
        else:
            ax.set_ylabel("Weighted Counts", fontsize=14)

        ax.set_yscale("log")

        ax.legend(title="Predicted Class")

        ax.text(
            1,
            1,
            f"# Events: {len(predictions)}",
            fontsize=14,
            ha="right",
            va="bottom",
            transform=ax.transAxes,
        )
        ax.text(
            0,
            1,
            process_tag,
            fontsize=14,
            ha="left",
            va="bottom",
            transform=ax.transAxes,
        )

        outpath = pjoin(outdir, f"{quantity_name}.pdf")
        fig.savefig(outpath)
        plt.close(fig)


@cli.command()
@click.pass_context
@click.argument("input_dir")
@click.option(
    "-q", "--quantity", required=True, help="The quantity to compute the threshold."
)
@click.option(
    "-t", "--threshold", type=float, required=True, help="The threshold value."
)
def average(ctx, input_dir: str, quantity: str, threshold: float) -> None:
    """
    Given the set of predictions and the high-level features (e.g. mjj),
    compute the average image per class (QCD V / EWK V) for events that
    satisfy:

    quantity > threshold.
    """
    # Gather the data
    df, predictions, label_encoding = load_cache(input_dir)

    with open(pjoin(input_dir, "input_root_files.txt"), "r") as f:
        inputfile = f.readlines()[0]

    process_tag = get_process_tag_from_file(inputfile)

    outdir = pjoin(input_dir, "averaged")
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    plotter = ImagePlotter()

    # Load the images
    with open(pjoin(input_dir, "images.pkl"), "rb") as f:
        image_pixels = pickle.load(f)

    # Get the images for the events where quantity > threshold
    # and compute the average for these images.
    mask = df[quantity] > threshold
    classes = ["bkg", "signal"]
    for iclass, class_label in enumerate(
        tqdm(classes, desc="Plotting averaged images")
    ):
        image_mask = mask & (predictions == iclass)
        images = image_pixels[image_mask]
        weights = df["weight"][image_mask]

        avg_image = np.average(images, axis=0, weights=weights)
        # outdir = pjoin(input_dir, "plots")

        plotter.plot(
            image=avg_image,
            outdir=outdir,
            filename=f"{class_label}_{quantity}_gt_{threshold}.pdf",
            vmin=1e-3,
            vmax=6e-2,
            cbar_label="Average Energy (GeV)",
            left_label=process_tag,
            right_label="predict : "
            + class_label
            + f"({sum(image_mask)}/{len(image_pixels)})",
        )


@cli.command()
@click.pass_context
@click.argument("input_dir")
@click.option(
    "-s",
    "--sequence-type",
    required=False,
    default="validation",
    help="The type of sequence: training or validation.",
)
def evaluate(ctx, input_dir: str, sequence_type: str) -> None:
    """
    Evalute the accuracy of the pre-trained model on full sequence.
    """
    loader = TrainingLoader(input_dir)

    model = loader.get_model()
    sequence = loader.get_sequence(sequence_type)

    sequence.batch_size = int(1e3)
    sequence.batch_buffer_size = 100

    model.evaluate(sequence)


if __name__ == "__main__":
    cli()
